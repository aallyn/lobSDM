---
title: "Juvenile Lobster Species Distribution Model"
format: 
  html:
    toc: true
    self-contained: true
    date: "Updated on: `r Sys.Date()`"
    author: Andrew Allyn
    code-fold: true
    code-wrap: true
    # include-in-header: polyfill.min.js
execute:
  echo: true
  message: false
  warning: false
editor: source
runtime: shiny
---

# Aim
The aim of this markdown document is to fit and project a spatio-temporal species distribution model for juvenile lobster under future climate change scenarios. 

# Approach 
## Model data
To meet this aim, we leverage catch data from mutliple different fisheries-independent bottom trawl surveys, including the NOAA Northeast Fisheries Science Center spring/fall survey, the Department of Fisheries and Oceans Canada spring/summer suvey, the Maine-New Hampshire spring/fall survey and the Massachusetts spring/fall survey. After compiling the different datasets, we filtered and classified lobster to juvenile lobsters if the length of the individuals was less than 8.2 cm (see `here::here("Code/1_CleanandSubsetCatchData.R")` for details). At each unique tow location, we then multiplied the number of individuals by the weight at length (*where did this come from*) to get an overall measurement of juvenile lobster biomass at each tow location. This defined our response variable and the "distribution and abundance" component to the spatio-temporal SDM. To describe variation in juvenile lobster biomass, we then extracted environmental covariates at each unique tow location, using bottom depth data from NOAA Etopo1 maps and bottom temperature from GLORYs (see `here::here("Code/GLORYs_download.ipynb")` and `here::here("Code/GLORYs_processing.ipynb")` for GLORYs data download and processing information and `here::here("Code/Extract/Covariates")` for extraction details). Finally, we joined the environmental covariate dataset to the juvenile lobster biomass data and imputed 0 biomass values for any tows present in the environmental dataset that were not in the juvenile lobster biomass data as these represent "absences", which were not explictly recorded by any of the surveys. 

## Model framework
We are using the spatio-temporal, mixed effects, species distribution modeling framework in `sdmTMB` to describe, understand, and predict juvenile lobster biomass. One way of conceptualizing this modeling framework is as a traditional, "environment-only" species distribution model that includes additional bells and whistles. In particular, like the traditional, "environment-only" SDMs, we can include fixed effects for environmental covariates thought to influence a species distribution and abundance. Conceding there are likely a lot of other environmental or biological processes influencing speices occurrence patterns, these spatio-temporal models can also account for unmeasured, persistent spatial variation or ephemeral spatio-temporal variation, and allow for autoregressive structures on any of the time-varying components (for example, season-year intercepts, or the spatio-temporal variability) with random effects.

There are a few additional components specific to our modeling framework. First, we include "survey" as a factor to account for systematic biases across the different bottom trawl surveys. This factor is essentially going to try to soak up variation among surveys that is purely related to differences in survey vessels/sampling techniques, as opposed to true variation in the biomass of juvenile lobster at a location. Second, rather than an annual time step, we are going to use a seasonal time step for our model, such that for a given year, we will be modeling the spring, summer and fall seasons. Moreover, we include a main effect and a spatially-varying random effect for sesason such that not only can a given season, on average, have higher/lower biomass across the domain, but this relationship can vary spatially. 

Drawing from [`sdmTMB`'s model description guide](https://pbs-assess.github.io/sdmTMB/articles/model-description.html), the full, target model, can then be written as

$$
\begin{aligned}
\mathbb{E}[y_{\boldsymbol{s},t}] &= \mu_{\boldsymbol{s},t},\\
\mu_{\boldsymbol{s},t} &=
f^{-1} \left( \boldsymbol{X}^{\mathrm{main}}_{\boldsymbol{s},t} \boldsymbol{\beta} +
O_{\boldsymbol{s},t} +
% \alpha_g +
\boldsymbol{X}^{\mathrm{tvc}}_{\boldsymbol{s},t} \boldsymbol{\gamma_t} +
\boldsymbol{X}^{\mathrm{svc}}_{\boldsymbol{s},t} \zeta_{\boldsymbol{s}} +
\omega_{\boldsymbol{s}} +
\epsilon_{\boldsymbol{s},t} \right),
\end{aligned}
$$

where

-   $y_{\boldsymbol{s},t}$ represents the juvenile biomass at point $\boldsymbol{s}$ and season-year $t$;
-   $\mu$ represents the mean;
-   $f$ represents a link function (e.g., log or logit) and $f^{-1}$ represents its inverse;
-   $\boldsymbol{X}^{\mathrm{main}}$, $\boldsymbol{X}^{\mathrm{tvc}}$, and $\boldsymbol{X}^{\mathrm{svc}}$ represent design matrices (the superscript identifiers 'main' = main effects, 'tvc' = time varying coefficients, and 'svc' = spatially varying coefficients);
-   $\boldsymbol{\beta}$ represents a vector of fixed-effect coefficients (i.e., depth and seasonal average bottom temperature);
-   $O_{\boldsymbol{s},t}$ represents an offset: a covariate (usually log transformed) with a coefficient fixed at one;
<!-- -   $\alpha_{g}$ represents random intercepts by group $g$, $\alpha_{g}\sim \mathrm{N}(0,\sigma^2_\alpha)$; -->
-   $\gamma_{t}$ represents time-varying coefficients (a random walk), $\gamma_{t} \sim \mathrm{N}(\gamma_{t-1},\sigma^2_\gamma)$;
-   $\zeta_{\boldsymbol{s}}$ represents the season spatially varying coefficient (a random field), $\zeta_{\boldsymbol{s}} \sim \mathrm{MVN}(\boldsymbol{0},\boldsymbol{\Sigma}_\zeta)$;
-   $\omega_{\boldsymbol{s}}$ represents a spatial component (a random field), $\omega_{\boldsymbol{s}} \sim \mathrm{MVN}(\boldsymbol{0},\boldsymbol{\Sigma}_\omega)$; and
-   $\epsilon_{\boldsymbol{s},t}$ represents a spatiotemporal component (a random field), $\epsilon_{\boldsymbol{s},t} \sim \mathrm{MVN}(\boldsymbol{0},\boldsymbol{\Sigma}_{\epsilon})$.

In working towards this full, target, model, we fit a baseline model (without spatial variation or spatio-temporal variation), and then a spatial model (with spatial varation, but still without spatio-temporal variation).

# Analysis 
## Data set up
We now step through our analysis process after bringing in some necessary libraries and generating some helpful functions to work with and visualize sdmTMB model output. 
```{r}
#| label: Libraries and preliminaries
#| echo: false
#| message: false
#| warning: false
#| include: false

library(tidyverse)
library(rnaturalearth)
library(rnaturalearthdata)
library(sdmTMB)
library(sdmTMBextra)
library(ggeffects)
library(shiny)
library(patchwork)
library(forecast)

source(here::here("Code/sdmTMB_Validation_Functions.R"))

# Scaling/unscaling function to facilitate model convergence
set.seed(13)
x <- rnorm(100)

scaled_x <- scale(x)
unscaled_x <- as.numeric((scaled_x * attr(scaled_x, "scaled:scale")) + attr(scaled_x, "scaled:center"))
# all.equal(x, unscaled_x)

scaled<- function(x, center, scale){
  (x - center) / scale
}

unscale <- function(scaled_x, center, scale) {
  if (is.null(attr(scaled_x, "scaled:scale")) == F) {
    # (scaled_x * sd) + m
    (scaled_x * attr(scaled_x, "scaled:scale")) + attr(scaled_x, "scaled:center")
  }
  if (is.null(attr(scaled_x, "scaled:scale")) == T) {
    (scaled_x * scale) + center
  }
}

unscale_aja <- function(scaled_x, orig_mean, orig_sd) {
  (scaled_x * orig_sd) + orig_mean
}

# Function to plot smooth effects
plot_smooths<- function(mod_fit, n_preds = 100, y_lab = "Predicted Biomass", rescale_means = NULL, rescale_sds = NULL){
  # Get smooth terms from the model
  formula_terms <- as.character(mod_fit$smoothers$labels)  # Right-hand side of formula
  
  # Clean up to get just the variable names
  smooth_terms <- gsub("\\)", "", gsub("s\\(", "", formula_terms))
  
  # Create prediction data frame for all smooth terms
  all_preds <- lapply(smooth_terms, function(term) {
    # Generate term string
    term_string <- paste0(term, paste0(" [n=", n_preds, "]"))

    # Pass to ggpredict
    pred <- ggpredict(mod_fit, terms = term_string)

    # Unscale for plotting?
    pred$smooth_term <- term
    if(!is.null(rescale_means) & !is.null(rescale_sds)){
      pred$x_raw <- unscale_aja(pred$x, rescale_means[[gsub("_scaled", "", term)]], rescale_sds[[gsub("_scaled", "", term)]])
    }
    pred$smooth_term <- term
    return(pred)
  })
  
  # Combine all predictions
  pred_data <- data.frame(bind_rows(all_preds))

  # Create the plot
  p <- ggplot() +
    geom_ribbon(data = pred_data, aes(x = x_raw, ymin = conf.low, ymax = conf.high, fill = smooth_term), alpha = 0.1, color = NA) +
    geom_line(data = pred_data, aes(x = x_raw, y = predicted, color = smooth_term), linewidth = 1) +
    labs(
      x = "Predictor value",
      y = y_lab
    ) +
    theme(
      text = element_text(size = 14),
      legend.position = "bottom"
    ) +
    facet_wrap(~ gsub("_scaled", "", smooth_term), scales = "free_x") +
    theme_bw()

  return(p)
}

# Base map land info
region <- ne_countries(scale = "medium", continent = "North America", returnclass = "sf")
states <- ne_states(country = c("United States of America", "Canada"), returnclass = "sf")

lat_lims <- c(35.2, 48)
lon_lims<- c(-76, -56.2)
```

Next, we can load in the model dataset and do some quick prepping steps, including filtering to just have the juvenile observations, and then scaling our environmental covariates to facilitate model conergence. There is also an incredibly large biomass value (~2000 kg!) and for now, we are going to remove that as it falls so far outside the distribution of catches.
```{r}
#| label: Loading and prepping data
#| echo: true
#| message: false
#| warning: false

all_mod_data<- readRDS(here::here("Data/Derived/all_model_data.rds")) |>
  mutate(survey = factor(survey, levels = c("NEFSC", "DFO", "ME_NH", "MA")))

# Focus on just lobster, and during GLORYs time series
year_min <- 1993
year_max <- 2023

red_mod_data <- all_mod_data |>
  dplyr::filter(life_class == "juvenile") |>
  dplyr::filter(between(year, year_min, year_max)) 

# summary(red_mod_data)

# Still some weird NA biomass values to figure out, dropping those for now
mod_data<- red_mod_data |>
  drop_na(total_biomass)
# summary(mod_data)

# What the heck is going on with that 2014 value?
t<- mod_data[which.max(mod_data$total_biomass),]
# plot(mod_data$total_biomass)

# Doesn't seem like there is anyway that point is real.
mod_data <- mod_data[-which.max(mod_data$total_biomass), ] |>
  ungroup()
# plot(mod_data$total_biomass)

# Scale/center covariates
# Get means and sds
column_means <- colMeans(mod_data[, c("Depth", "BT_seasonal")], na.rm = TRUE)
column_sds <- apply(mod_data[, c("Depth", "BT_seasonal")], 2, sd, na.rm = TRUE)

# Scale the data
mod_data <- mod_data |>
  mutate(across(
    c(Depth, BT_seasonal),
    ~ (. - mean(., na.rm = TRUE)) / sd(., na.rm = TRUE),
    .names = "{.col}_scaled"
  ))
```

With the model prep complete, we then need to do a bit of additional coding to facilitate fitting the season-year time step model, and especially, fitting a main and spatially-varying coefficient for `season`.

```{r}
#| label: Season time step work
#| echo: true
#| message: false
#| warning: false

# Going to want to have a continuous time column
all_years<- seq(from = min(mod_data$year), to = max(mod_data$year))
seasons<- c("Spring", "Summer", "Fall")
time_fac_levels<- paste(rep(all_years, each = length(unique(seasons))), seasons, sep = "_")
time_ints<- as.numeric(factor(time_fac_levels, levels = time_fac_levels))

mod_data <- mod_data |>
  mutate(season = factor(season, levels = seasons),
         year_season_fac = factor(paste(year, season, sep = "_"), levels = time_fac_levels),
         year_season_int = as.numeric(year_season_fac)) %>%
  arrange(year_season_int)

# Now for the model matrix trickery
mm_season <- model.matrix(~ 0 + factor(season), data = mod_data)
# mm_year <- model.matrix(~ 0 + factor(est_year), data = dat) 

mod_data <- mod_data |>
  dplyr::select(!contains("factor")) |>
  cbind(mm_season) |>
  #   cbind(mm_year) |>
  as_tibble()

fa <- names(mod_data)[grepl("factor", names(mod_data))]
fo <- paste0("`", paste(fa, collapse = "` + `"), "`")
svc <- as.formula(paste("~", fo))
```

Finally, let's make an edit so that we hold out some data to then validate the prediction skill of the model. Here, we leave out the most recent 5 years of observations across each of the 3 seasons, totaling 15 "model time steps."
```{r}
hold_out_ints<- as.numeric(factor(time_fac_levels, levels = time_fac_levels))[(length(time_ints)-15): length(time_ints)]
hold_out_yr_seas<- time_fac_levels[hold_out_ints]

mod_data_red<- mod_data |>
  filter(!year_season_fac %in% hold_out_yr_seas)
```

## sdmTMB mesh
sdmTMB, and other common spatio-temporal modeling approaches, use a spatial mesh to facilitate estimating random spatial, and spatio-temporal effects, as Gaussian Markov Random Fields, approximated by Spatial Partial Differential Equations. Here, we create a mesh and note that we will likely want to return to evaluate alternative mesh structures. Owen Liu has some potentially useful and [helpful code](https://github.com/owenrliu/eDNA_eulachon/blob/63a1b4d21fa4ffbc629cbb0657bc032998565f17/scripts/eulachon_sdms.Rmd#L217) for doing something similar. 
```{r}
#| label: sdmTMB mesh
#| echo: true
#| message: false
#| warning: false

# Add long/lat column to model data 
mod_data_red <- mod_data_red %>%
  sdmTMB::add_utm_columns(ll_names = c("longitude", "latitude"), units = "km") 

# Create sdmTMB mesh -- 
sdmTMB_mesh <- sdmTMB::make_mesh(mod_data_red, xy_cols = c("longitude", "latitude"), type = "cutoff", cutoff = 0.5)
```

```{r}
#| label: Plot sdmTMB mesh
#| echo: false
#| code-fold: false
#| message: false
#| warning: false
plot(sdmTMB_mesh)
```

## sdmTMB fits
With the data and mesh, we can now start fitting the models with calls to `sdmTMB`. For this we are going to fit three different models to represent the progressive influence of adding spatial and then spatio-temporal variation to a "baseline" model structure that includes fixed effects for environmental covariates, survey, and season, a random, spatially-varying effect for season, and finally an auto-regressive time-varying structure to the model intercepts, which will eventually facilitate predicting to future time steps.

Importantly, to implement a model with a fixed effect and spatially-varying coefficient for season, we need to do some adjustments to the underlying mapping of parameters. Specifically, we pool variances across all the seasons, rather than estimate seasonally-specific spatially-varying coefficient variances.  

We start with the "baseline" model.
```{r}
#| label: Baseline juvenile lobster SDM
#| echo: TRUE
#| warning: false

# Mapping to pool variances across seasons
n_seasons <- length(unique(mod_data_red$season)) 
tau_Z_map <- factor(cbind(rep(1, n_seasons)))

# Fit the model
fit_base<- sdmTMB(
  total_biomass ~ factor(season) + factor(survey) + s(Depth, k = 4) + s(BT_seasonal, k = 4),
  control = sdmTMBcontrol(map = list(ln_tau_Z = tau_Z_map)),
  data = mod_data_red,
  spatial = "off",
  # offset = dat_mod$swept,
  # anisotropy = TRUE,
  # share_range = TRUE,
  spatiotemporal = "off",
  spatial_varying = svc,
  time = "year_season_int",
  time_varying = ~ 0 + year_season_int,
  time_varying_type = "ar1",
  extra_time = time_ints,
  mesh = sdmTMB_mesh,
  family = tweedie(),
  silent = TRUE,
  do_fit = TRUE
)
```

Before we get too far ahead of ourselves, lets inspect this inital baseline model fit a bit as we are going to be building in complexity that is likely to generate some convergence issues and it could be helpful to do some simplifying here. The one "complex" piece here that could be adjusted without compromising our model objectives is probably the time-varying intercepts, estimated as a AR1 process. While this is a nice piece to facilitate forecasting to future years, we will have dynamic environmental variables as well as the spatio-temporal variation component, which both will be "varying" at each time step and also support model prediction to unsampled years. Given that, we can explore this parameter.

```{r}
#| label: Baseline juvenile lobster SDM tuning
#| echo: TRUE
#| warning: false

# First, quick look at the values
summary(fit_base)

# Extract AR1 coefficient for intercepts
fit_base$sd_report
pl <- as.list(fit_base$sd_report, "Estimate")
pls <- as.list(fit_base$sd_report, "Std. Error")

rho_est <- pl$rho_time_unscaled[1,1]
rho_se <- pls$rho_time_unscaled[1,1]

bound <- function(x) 2 * plogis(x) - 1

c(round(bound(rho_est - 1.96 * rho_se), 2), round(bound(rho_est), 2), round(bound(rho_est + 1.96 * rho_se), 2))
```

The combination of the SE overlapping 0 and then the relatively low overall parameter estimate (0.05), suggests this isn't a very strong AR1 process. In particular, as the rho parameter goes to 0, we approach a white noise/IID process. We then have a couple of different options. One option would be to fit this time_varying parameter as IID by placing it in the formula structure (`total_biomass ~ factor(season) + factor(survey) + s(Depth, k = 4) + s(BT_seasonal, k = 4) + (1|year_season_int)`). I *think* this is potentially going to create some issues when we go to validate the model prediction skill using the standard `predict` function, though think we should be able to get around that with (maybe using some of the projection methods?)

We can give it a shot and at least double check the model generates at least as good, or ideally better, fit to the training data.

```{r}
#| label: Baseline juvenile lobster SDM refit
#| echo: TRUE
#| warning: false

mod_data_red<- mod_data_red |>
    mutate(year_seas_fac = factor(year_season_int))

# Fit the model
if(!file.exists(here::here("Juve_YrSeasFac.rds")) | !file.exists(here::here("Juve_YrSeasFix.rds"))) {
  fit_base_yrseasfac <- sdmTMB(
    total_biomass ~ factor(season) + factor(survey) + s(Depth, k = 4) + s(BT_seasonal, k = 4) + (1|year_seas_fac),
    control = sdmTMBcontrol(map = list(ln_tau_Z = tau_Z_map)),
    data = mod_data_red,
    spatial = "off",
    # offset = dat_mod$swept,
    # anisotropy = TRUE,
    # share_range = TRUE,
    spatiotemporal = "off",
    spatial_varying = svc,
    time = "year_season_int",
    # time_varying = ~ 0 + year_season_int,
    time_varying = NULL,
    # time_varying_type = "ar1",
    extra_time = time_ints,
    mesh = sdmTMB_mesh,
    family = tweedie(),
    silent = TRUE,
    do_fit = TRUE
  )

  fit_base_yrseasfix <- sdmTMB(
    total_biomass ~ factor(season) + factor(survey) + s(Depth, k = 4) + s(BT_seasonal, k = 4),
    control = sdmTMBcontrol(map = list(ln_tau_Z = tau_Z_map)),
    data = mod_data_red,
    spatial = "off",
    # offset = dat_mod$swept,
    # anisotropy = TRUE,
    # share_range = TRUE,
    spatiotemporal = "off",
    spatial_varying = svc,
    time = "year_season_int",
    # time_varying = ~ 0 + year_season_int,
    time_varying = NULL,
    # time_varying_type = "ar1",
    extra_time = time_ints,
    mesh = sdmTMB_mesh,
    family = tweedie(),
    silent = TRUE,
    do_fit = TRUE
  )
  write_rds(fit_base_yrseasfac, here::here("Juve_YrSeasFac.rds"), compress = "gz")
  write_rds(fit_base_yrseasfix, here::here("Juve_YrSeasFix.rds"), compress = "gz")
} else {
  fit_base_yrseasfac<- readRDS(here::here("Juve_YrSeasFac.rds"))
  fit_base_yrseasfix<- readRDS(here::here("Juve_YrSeasFix.rds"))
}

# Some quick model comparisons, being cautious with just the AIC given the change in effects structure
knitr::kable(data.frame("Model" = c("Baseline", "Baseline - IID Season-Year", "Baseline - Constant Season-Year"), "AIC" = c(AIC(fit_base), AIC(fit_base_yrseasfac), AIC(fit_base_yrseasfix)), "Log Likelihood" = c(logLik(fit_base), logLik(fit_base_yrseasfac), logLik(fit_base_yrseasfix))), digits = 3)
```

A bit of the fork in the road here. There's isn't a reason based on model fit to the data to really choose using year as a constant or as IID as AICs are higher and log likelihoods are more negative. AIC is a bit suspect given the varying model structures and they aren't truly "nested" models. What do we see with the parameters for the IID? We know there wasn't much support for the AR1 process. Is there a lot of variability among time steps absorbed by the random effect to warrant its inclusion?
```{r}
yr_seas_effects<- tidy(fit_base_yrseasfac, effects = "ran_vals", conf.int = TRUE) |>
  mutate(Plot_Time = as.numeric(factor(term)))

ggplot(data = yr_seas_effects, aes(x = Plot_Time, y = estimate, ymin = conf.low, ymax = conf.high)) + 
  geom_point() +
  geom_errorbar() +
  stat_smooth() +
  theme_bw()
```

Not exactly the most helpful, seems to show almost a regime-like shift and then decline towards the later part of the the time series. Given all of this collective information, I think it will make sense to maybe let any of this variability be soaked up into the eventual spatial or spatio-temporal model terms by not including the "year_season" term in either the random effect or the time varying component. Will do another check on things after adding in the spatial variability.

```{r}
#| label: Spatial juvenile lobster SDM
#| echo: true
#| warning: false

# Fit the model or load it?
if(!file.exists(here::here("Juve_Sp_YrSeasAR1.rds")) | !file.exists(here::here("Juve_Sp_YrSeasAR1.rds"))){
  fit_sp_yrseasar1<- sdmTMB(
    total_biomass ~ factor(season) + factor(survey) + s(Depth, k = 4) + s(BT_seasonal, k = 4),
    control = sdmTMBcontrol(map = list(ln_tau_Z = tau_Z_map)),
    data = mod_data_red,
    spatial = "on",
    # offset = dat_mod$swept, 
    anisotropy = TRUE, 
    # share_range = TRUE,
    spatiotemporal = "off",
    spatial_varying = svc,
    time = "year_season_int",
    time_varying = ~ 0 + year_season_int,
    time_varying_type = "ar1",
    extra_time = time_ints,
    mesh = sdmTMB_mesh,
    family = tweedie(), 
    silent = TRUE,
    do_fit = TRUE
  )

   fit_sp_yrseas<- sdmTMB(
    total_biomass ~ factor(season) + factor(survey) + s(Depth, k = 4) + s(BT_seasonal, k = 4),
    control = sdmTMBcontrol(map = list(ln_tau_Z = tau_Z_map)),
    data = mod_data_red,
    spatial = "on",
    # offset = dat_mod$swept, 
    anisotropy = TRUE, 
    # share_range = TRUE,
    spatiotemporal = "off",
    spatial_varying = svc,
    time = "year_season_int",
    # time_varying = ~ 0 + year_season_int,
    # time_varying_type = "ar1",
    extra_time = time_ints,
    mesh = sdmTMB_mesh,
    family = tweedie(), 
    silent = TRUE,
    do_fit = TRUE
  )
  write_rds(fit_sp_yrseas, here::here("Juve_Sp_YrSeasAR1.rds"), compress = "gz")
  write_rds(fit_sp_yrseas, here::here("Juve_Sp_YrSeas.rds"), compress = "gz")
} else {
  fit_sp_yrseasar1<- readRDS(here::here("Juve_Sp_YrSeasAR1.rds"))
  fit_sp_yrseas<- readRDS(here::here("Juve_Sp_YrSeas.rds"))
}
```

How do things look now in terms of AIC and log likelihood?
```{r}
 # Quick comparison
  knitr::kable(data.frame("Model" = c("Year_Season AR1", "Year_Season_Fixed"), "AIC" = c(AIC(fit_sp_yrseas), AIC(fit_sp_yrseasar1)), "Log Likelihood" = c(logLik(fit_sp_yrseas), logLik(fit_sp_yrseasar1))), digits = 3)
```

Alright, that looks better and I think we can then go forward with adding in the spatio-temporal piece and keeping year_season as fixed. For what it is worth, when we implemented this model structure with an AR1 process on the spatio-temporal variation, we ran into gradient issues immediately. Fitting with a RW removed the error, though generated a warning about the Hessian matrix, signaling issues with resolving the uncertainty around fixed and random effects. It is still a bit unclear to me why this is happening, other than there is something going on with time_varying for both the intercepts and the spatio-temporal terms?

While trouble shooting that, proceeding with the constant "year_season" spatio-temporal model. 

```{r}
#| label: Spatio-temporal juvenile lobster SDM
#| echo: true
#| warning: false

# Fit the model or load it?
if(!file.exists(here::here("Juve_SpST.rds"))){
  fit_spst<- sdmTMB(
    total_biomass ~ factor(season) + factor(survey) + s(Depth, k = 4) + s(BT_seasonal, k = 4),
    control = sdmTMBcontrol(map = list(ln_tau_Z = tau_Z_map)),
    data = mod_data_red,
    spatial = "on",
    # offset = dat_mod$swept, 
    anisotropy = TRUE, 
    share_range = FALSE,
    spatiotemporal = "ar1",
    spatial_varying = svc,
    time = "year_season_int",
    # time_varying = ~ 0 + year_season_int,
    time_varying = NULL,
    # time_varying_type = "ar1",
    extra_time = time_ints, # This doesn't work with full time_ints and ar1, it will work but with convergence issues for full time_ints and RW. With just fit time_ints and ar1, also NA issue.
    mesh = sdmTMB_mesh,
    family = tweedie(), 
    silent = TRUE,
    do_fit = TRUE
  )
  write_rds(fit_spst, here::here("Juve_SpST.rds"), compress = "gz")
} else {
  fit_spst<- readRDS(here::here("Juve_SpST.rds"))
}
```

## sdmTMB fits evaluation and inferences
With the three models fit, we can now evaluate each of them. Residual checks with spatio-temporal models are infamously difficult to interpret (see [here](https://pbs-assess.github.io/sdmTMB/articles/residual-checking.html) and [here](https://github.com/pbs-assess/sdmTMB/discussions/327) for more details and information). Here we start by looking at the q-q plots and fitted vs. predicted residuals.

```{r, results='hide'}
#| label: Residual checks
#| echo: true
#| warning: false

# Make a tibble with fitted model as its own column so we can map different functions to the models
all_fits<- list("Base" = fit_base_yrseasfix, "Sp" = fit_sp_yrseas, "SpST" = fit_spst)

fits_df<- tibble("Name" = c("fit_base", "fit_sp", "fit_spst"), "Mod" = all_fits)

# Now, DHARMa residuals
get_DHARMa_nested<- function(fit, nsim_use = 100, type_use = "mle-mvn"){
  out<- simulate(fit, nsim = nsim_use, type = type_use) |>
    dharma_residuals(fit, plot = FALSE, return_DHARMa = TRUE)
  return(out)
}

fits_df<- fits_df |>
  mutate(DHARMa_resids = map(Mod, get_DHARMa_nested))

# Saving plots
plot_DHARMa_nested<- function(fit, name){
  # Extract residuals and fitted values
  residuals <- residuals(fit)
  fitted_vals <- predict(fit)$est
  
  # Create diagnostic plots
  p1 <- ggplot(data.frame(residuals = residuals), aes(sample = residuals)) +
    stat_qq() +
    stat_qq_line() +
    theme_bw() +
    ggtitle("Normal Q-Q Plot of Residuals")
  
  p2 <- ggplot(data.frame(fitted = fitted_vals, residuals = residuals), aes(x = fitted, y = residuals)) +
    geom_point() +
    geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
    theme_bw() +
    ggtitle("Residuals vs. Fitted Values")
    
    # Arrange plots in a grid
    out<- p1 + p2 + plot_layout(ncol = 2) + plot_annotation(title = name)
    return(out)
}

fits_df<- fits_df |>
  mutate(DHARMa_plots = map2(Mod, Name, plot_DHARMa_nested))  
all_diag<- fits_df$DHARMa_plots[[1]] / fits_df$DHARMa_plots[[2]] / fits_df$DHARMa_plots[[3]] 
ggsave("~/GitHub/lobSDM/Figures/JuveLobDiagnostics.png", all_diag)

```

```{r}
all_diag
```

After the residual checks, we can then look at model fit to the data using AIC as one measure of the model fit to the data.
```{r}
knitr::kable(data.frame("Model" = c("Baseline", "Baseline + Spatial Variation", "Baseline + Spatial + Spatio-temporal Variation"), "AIC" = c(AIC(fits_df$Mod[[1]]), AIC(fits_df$Mod[[2]]), AIC(fits_df$Mod[[3]])), "Log Likelihood" = c(logLik(fits_df$Mod[[1]]), logLik(fits_df$Mod[[2]]), logLik(fits_df$Mod[[3]]))), digits = 3)
```

The model evaluation statistics capture how well the model fit the data it was trained on. This is certainly an important piece of information, it is just one piece of the puzzle and we can take an addtional step to validate the model, which measures the model's capcity to predict to data it has not seen. Given our interest in using the model to make forecasts or projections, we held out the most recent 5 years of data during the model fitting process. We can now make predictions to those hold-out points and then calculate any number of prediction skill statistics. First, we generate the predictions. 

```{r}
#| label: Model validation
#| echo: true
#| warning: false

# Get the prediction data frame
pred_data_use<- mod_data |>
  filter(year_season_int %in% hold_out_ints)

pred_sdmTMB_nested<- function(fit, pred_data = pred_data_use){
  pred_out<- predict(fit, newdata = pred_data, type = "response")
  return(pred_out)
}

fits_df<- fits_df |>
  mutate(Preds = map(Mod, pred_sdmTMB_nested))
```

Next, we can calculate a variey of prediction statistics to validate the model skill. To start, we will show a table with two different measures of prediction skill: the Pearson Correlation Coefficient (CorrCeff) and the Root Mean Squared Error (RMSE). The CorrCoeff provides insights about whether model predictions and observations follow similar patterns, though these are relative and do not necessarily represent the accuracy of the model predictions. For that component of model skill, we use RMSE, which does represent the difference on the response scale between model predictions and observations. 
```{r}
#| label: Model validation table
#| echo: true
#| warning: false

pred_table<- fits_df |>
  mutate(Corr_Coeff = pmap_dbl(list(df = Preds, obs_col = "total_biomass", mod_col = "est"), pearson_corr_coeff_func),
  RMSE = pmap_dbl(list(df = Preds, obs_col = "total_biomass", mod_col = "est"), rmse_func)) |>
  dplyr::select(Name, Corr_Coeff, RMSE)

knitr::kable(pred_table, digits = 3)
```

Along side the prediction table, we can also visualize multiple aspects of prediction skill using a Taylor Diagram. The Taylor diagram provides a succinct picture of a model’s predictive ability. For each Taylor diagram, there is a reference point (shown by the gold-star) at [1,0]. This point indicates a model with perfect correlation between observations and predictions, no error, and the correct level of spatial variability. The relative strength of different models for different species is assessed by where the species-model point falls on the Taylor diagram, where correlation between observations and model predictions increases moving along the correlation coefficient arcs, reaching perfect correlation at the horizontal line with y = 0, model root mean square error decreases proportionally with the radial distance of each point to the reference point at [1,0], and agreement between observed variability and predicted variability increases with radial distances from the origin [0,0].

```{r}
#| label: Calculate and plot Taylor Diagram
#| echo: true
#| warning: false
#| fig-width: 10
#| fig-height: 8

# Data prep, need one big data frame with a "group" column for each mode
td_dat<- fits_df |>
  dplyr::select(Name, Preds) |>
  unnest(cols = c(Preds)) |>
  mutate(Model = factor(Name, levels = c("fit_base", "fit_sp", "fit_spst"), labels = c("Baseline", "Baseline + Spatial Variation", "Baseline + Spatial + Spatio-temporal Variation")))

# Make the plot
td_plot<- taylor_diagram_func(dat = td_dat, obs = "total_biomass", mod = "est", group = "Model", out.file = "~/GitHub/lobSDM/Figures/Juve_Model_TD.png", grad.corr.lines = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1), pcex = 1, cex.axis = 1, normalize = TRUE, mar = c(5, 4, 6, 6), sd.r = 1, fill.cols = c('#1b9e77','#d95f02','#7570b3'), color.cols = rep("black", 3), shapes = c(21, 22, 24), alpha = 0.5, example = FALSE)
td_plot
```
